{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "984024c6-10e4-4887-a8a1-fc962122569b",
   "metadata": {},
   "source": [
    "<H1>Unit Tests</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06427349-9a17-4ec0-b46b-8e9008249483",
   "metadata": {},
   "source": [
    "<H3>1. Install Packages</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c1c63a0-cabf-4526-82ca-5f44892665c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytest==8.3.2 in /home/k-irw/miniconda3/envs/mlflow-c2f694fcc51c2a8f873efe7e2ebd5acc40584b07/lib/python3.10/site-packages (8.3.2)\n",
      "Requirement already satisfied: iniconfig in /home/k-irw/miniconda3/envs/mlflow-c2f694fcc51c2a8f873efe7e2ebd5acc40584b07/lib/python3.10/site-packages (from pytest==8.3.2) (2.1.0)\n",
      "Requirement already satisfied: packaging in /home/k-irw/miniconda3/envs/mlflow-c2f694fcc51c2a8f873efe7e2ebd5acc40584b07/lib/python3.10/site-packages (from pytest==8.3.2) (23.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /home/k-irw/miniconda3/envs/mlflow-c2f694fcc51c2a8f873efe7e2ebd5acc40584b07/lib/python3.10/site-packages (from pytest==8.3.2) (1.6.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/k-irw/miniconda3/envs/mlflow-c2f694fcc51c2a8f873efe7e2ebd5acc40584b07/lib/python3.10/site-packages (from pytest==8.3.2) (1.3.0)\n",
      "Requirement already satisfied: tomli>=1 in /home/k-irw/miniconda3/envs/mlflow-c2f694fcc51c2a8f873efe7e2ebd5acc40584b07/lib/python3.10/site-packages (from pytest==8.3.2) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/k-irw/miniconda3/envs/mlflow-c2f694fcc51c2a8f873efe7e2ebd5acc40584b07/lib/python3.10/site-packages (from exceptiongroup>=1.0.0rc8->pytest==8.3.2) (4.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pytest==8.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9afbb78b-29aa-454d-a2d4-a616c136784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32869916-3bbc-4982-a70a-74fe7dc1e97d",
   "metadata": {},
   "source": [
    "<H3>2. Create Test Data</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662d19ba-1235-4d3c-a4f7-a5f7c5f39caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cat1_values(row):\n",
    "    if row['category_1'] == 0:\n",
    "        return 'Alpha'\n",
    "    elif row['category_1'] == 1:\n",
    "        return 'Alpha'\n",
    "    else:\n",
    "        return 'Beta'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4846dc-26ff-4bbd-abe4-daace6b66cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cat2_values(row):\n",
    "    if row['category_2'] == 0:\n",
    "        return 'A'\n",
    "    elif row['category_2'] == 1:\n",
    "        return 'B'\n",
    "    elif row['category_2'] == 2:\n",
    "        return 'C'\n",
    "    elif row['category_2'] == 3:\n",
    "        return 'D'\n",
    "    elif row['category_2'] == 4:\n",
    "        return 'E'\n",
    "    else:\n",
    "        return 'F'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201e7bd6-5ccd-4ac7-baef-6b24ef1a918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cat3_values(row):\n",
    "    if row['category_3'] == 0:\n",
    "        return 'North'\n",
    "    elif row['category_3'] == 1:\n",
    "        return 'North'\n",
    "    elif row['category_3'] == 2:\n",
    "        return 'South'\n",
    "    elif row['category_3'] == 3:\n",
    "        return 'East'\n",
    "    else:\n",
    "        return 'West'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7c55ca-676e-4660-a01b-12a090c2fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cat4_values(row):\n",
    "    if row['category_4'] == 0:\n",
    "        return 'Up'\n",
    "    elif row['category_4'] == 1:\n",
    "        return 'Up'\n",
    "    elif row['category_4'] == 2:\n",
    "        return 'Up'\n",
    "    else:\n",
    "        return 'Down'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "656c8a60-6c22-4179-b644-49d134ae87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cat5_values(row):\n",
    "    if row['category_5'] == 0:\n",
    "        return 'Front'\n",
    "    elif row['category_5'] == 1:\n",
    "        return 'Back'\n",
    "    elif row['category_5'] == 2:\n",
    "        return 'Left'\n",
    "    elif row['category_5'] == 3:\n",
    "        return 'Right'\n",
    "    else:\n",
    "        return 'Center'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcd5f91c-195e-4ee8-bb15-a011c1cb8326",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cat6_values(row):\n",
    "    if row['category_6'] == 0:\n",
    "        return 'Black'\n",
    "    elif row['category_6'] == 1:\n",
    "        return 'Red'\n",
    "    elif row['category_6'] == 2:\n",
    "        return 'Orange'\n",
    "    elif row['category_6'] == 3:\n",
    "        return 'Yellow'\n",
    "    elif row['category_6'] == 4:\n",
    "        return 'Green'\n",
    "    elif row['category_6'] == 5:\n",
    "        return 'Blue'\n",
    "    elif row['category_6'] == 6:\n",
    "        return 'Indigo'\n",
    "    elif row['category_6'] == 7:\n",
    "        return 'Violet'\n",
    "    else:\n",
    "        return 'White'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01fbd4e1-b54d-4e6e-ad2d-527432ee33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_target_values(row):\n",
    "    if row['target'] == 0:\n",
    "        return 'foo'\n",
    "    elif row['target'] == 1:\n",
    "        return 'foo'\n",
    "    else:\n",
    "        return 'bar'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1f5c33f-a135-4bd4-bd22-e00264d3d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_data():\n",
    "\n",
    "    '''\n",
    "    Generates a DataFrame with random data for testing purposes.\n",
    "    '''\n",
    "\n",
    "    random.seed(42)    \n",
    "    random_integer = random.randint(20000, 50000)\n",
    "\n",
    "    list_1 = [random.randint(0, 2) for _ in range(random_integer)]\n",
    "    list_2 = [random.randint(0, 5) for _ in range(random_integer)]\n",
    "    list_3 = [random.randint(0, 4) for _ in range(random_integer)]\n",
    "    list_4 = [random.randint(0, 3) for _ in range(random_integer)]\n",
    "    list_5 = [random.randint(0, 5) for _ in range(random_integer)]\n",
    "    list_6 = [random.randint(0, 9) for _ in range(random_integer)]\n",
    "    list_7 = list(range(1,(random_integer + 1)))\n",
    "    list_8 = list(range(random_integer,0,-1))\n",
    "    list_9 = [random.randint(20, 80) for _ in range(random_integer)]\n",
    "    list_10 = [random.randint(0, 2) for _ in range(random_integer)]\n",
    "\n",
    "    data = {\n",
    "        'category_1': list_1,\n",
    "        'category_2': list_2,\n",
    "        'category_3': list_3,\n",
    "        'category_4': list_4,\n",
    "        'category_5': list_5,\n",
    "        'category_6': list_6,\n",
    "        'feature_1': list_6,\n",
    "        'feature_2': list_7,\n",
    "        'feature_3': list_8,\n",
    "        'feature_4': list_9,\n",
    "        'target': list_10\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    df['category_1'] = df.apply(get_cat1_values, axis=1)\n",
    "    df['category_2'] = df.apply(get_cat2_values, axis=1)\n",
    "    df['category_3'] = df.apply(get_cat3_values, axis=1)\n",
    "    df['category_4'] = df.apply(get_cat4_values, axis=1)\n",
    "    df['category_5'] = df.apply(get_cat5_values, axis=1)\n",
    "    df['category_6'] = df.apply(get_cat6_values, axis=1)\n",
    "    df['target'] = df.apply(get_target_values, axis=1)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b5ce80b-ea37-4c09-9a8b-c4aea296ea49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40952, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = random_data()\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73eb8b9f-05eb-4e65-a77f-30ab2ee25f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>category_4</th>\n",
       "      <th>category_5</th>\n",
       "      <th>category_6</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alpha</td>\n",
       "      <td>F</td>\n",
       "      <td>North</td>\n",
       "      <td>Up</td>\n",
       "      <td>Front</td>\n",
       "      <td>White</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>40952</td>\n",
       "      <td>64</td>\n",
       "      <td>bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alpha</td>\n",
       "      <td>E</td>\n",
       "      <td>South</td>\n",
       "      <td>Up</td>\n",
       "      <td>Left</td>\n",
       "      <td>Green</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>40951</td>\n",
       "      <td>50</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beta</td>\n",
       "      <td>C</td>\n",
       "      <td>North</td>\n",
       "      <td>Up</td>\n",
       "      <td>Front</td>\n",
       "      <td>Red</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40950</td>\n",
       "      <td>36</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alpha</td>\n",
       "      <td>E</td>\n",
       "      <td>North</td>\n",
       "      <td>Up</td>\n",
       "      <td>Center</td>\n",
       "      <td>White</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>40949</td>\n",
       "      <td>46</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alpha</td>\n",
       "      <td>D</td>\n",
       "      <td>South</td>\n",
       "      <td>Up</td>\n",
       "      <td>Center</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>40948</td>\n",
       "      <td>20</td>\n",
       "      <td>bar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category_1 category_2 category_3 category_4 category_5 category_6  \\\n",
       "0      Alpha          F      North         Up      Front      White   \n",
       "1      Alpha          E      South         Up       Left      Green   \n",
       "2       Beta          C      North         Up      Front        Red   \n",
       "3      Alpha          E      North         Up     Center      White   \n",
       "4      Alpha          D      South         Up     Center     Yellow   \n",
       "\n",
       "   feature_1  feature_2  feature_3  feature_4 target  \n",
       "0          8          1      40952         64    bar  \n",
       "1          4          2      40951         50    foo  \n",
       "2          1          3      40950         36    foo  \n",
       "3          8          4      40949         46    foo  \n",
       "4          3          5      40948         20    bar  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "165d9810-62bd-4885-8552-3a3443b0714b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "foo    27264\n",
       "bar    13688\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cce409-f3b0-41df-9776-113c9f67e380",
   "metadata": {},
   "source": [
    "<H3>3. Test Data Split</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0df36a2-655a-4c8a-9b7f-fa70a3f16d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_data_split():\n",
    "    '''\n",
    "    Test train_test_split to determine if train and test data are split approx 80/20.\n",
    "    '''\n",
    "    \n",
    "    data = random_data()\n",
    "    \n",
    "    train, test = train_test_split(data, test_size=0.20, random_state=42)\n",
    "    \n",
    "    assert type(train) == pd.core.frame.DataFrame\n",
    "    assert type(test) == pd.core.frame.DataFrame\n",
    "    \n",
    "    assert train.shape[0] == int(data.shape[0] * .80)\n",
    "    assert test.shape[0] == math.ceil(data.shape[0] * .20)\n",
    "\n",
    "    print(type(train))\n",
    "    print(type(test))\n",
    "    print(train.shape)\n",
    "    print(test.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfa3ebb8-a027-4f6b-91ba-d45fa45fefa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(32761, 11)\n",
      "(8191, 11)\n"
     ]
    }
   ],
   "source": [
    "test_data_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d191ffb3-26c8-4a74-8ed7-6596e0f841a8",
   "metadata": {},
   "source": [
    "<H3>4. Test Process Data</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "329219ef-b1a1-4f74-9006-b74c19e0fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_data(\n",
    "    X, categorical_features=[], label=None, training=True, encoder=None, lb=None\n",
    "):\n",
    "\n",
    "    if label is not None:\n",
    "        y = X[label]\n",
    "        X = X.drop([label], axis=1)\n",
    "    else:\n",
    "        y = np.array([])\n",
    "\n",
    "    X_categorical = X[categorical_features].values\n",
    "    X_continuous = X.drop(*[categorical_features], axis=1)\n",
    "\n",
    "    if training is True:\n",
    "        encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "        lb = LabelBinarizer()\n",
    "        X_categorical = encoder.fit_transform(X_categorical)\n",
    "        y = lb.fit_transform(y.values).ravel()\n",
    "    else:\n",
    "        X_categorical = encoder.transform(X_categorical)\n",
    "        try:\n",
    "            y = lb.transform(y.values).ravel()\n",
    "        # Catch the case where y is None because we're doing inference.\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    X = np.concatenate([X_continuous, X_categorical], axis=1)\n",
    "    return X, y, encoder, lb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d11ecde6-456b-451a-843e-3c1a639f18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_process_data():\n",
    "    \n",
    "    '''\n",
    "    Test process_data function to determine if correct data types are returned.\n",
    "    '''\n",
    "    \n",
    "    data = random_data()\n",
    "    train, test = train_test_split(data, test_size=0.20, random_state=42)\n",
    "    \n",
    "    cat_features = [\n",
    "        'category_1',\n",
    "        'category_2',\n",
    "        'category_3',\n",
    "        'category_4',\n",
    "        'category_5',\n",
    "        'category_6'\n",
    "    ]\n",
    "    \n",
    "    X_train, y_train, encoder, lb = process_data(\n",
    "    X=train, categorical_features=cat_features, label=\"target\", training=True\n",
    "    )\n",
    "    \n",
    "    assert type(X_train) == np.ndarray\n",
    "    assert X_train.shape[0] == train.shape[0]\n",
    "\n",
    "    assert type(y_train) == np.ndarray\n",
    "    assert y_train.shape[0] == train.shape[0]\n",
    "\n",
    "    assert type(encoder) == OneHotEncoder\n",
    "    assert type(lb) == LabelBinarizer\n",
    "\n",
    "    \n",
    "    print(type(X_train))\n",
    "    print(X_train.shape)\n",
    "    \n",
    "    print(type(y_train))\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    print(type(encoder))\n",
    "    print(type(lb))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c80139d5-6ca0-495c-ae6a-f49578572c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(32761, 32)\n",
      "<class 'numpy.ndarray'>\n",
      "(32761,)\n",
      "<class 'sklearn.preprocessing._encoders.OneHotEncoder'>\n",
      "<class 'sklearn.preprocessing._label.LabelBinarizer'>\n"
     ]
    }
   ],
   "source": [
    "test_process_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a49419-7eb8-4830-9348-20bc4758c923",
   "metadata": {},
   "source": [
    "<H3>5. Test Train Model</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "699d3b2b-9850-4af7-8edb-cb471a954ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(X_train, y_train):\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28b52268-9e3a-4e4b-9ea1-f3982426e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_train_model():\n",
    "    '''\n",
    "    Test train_model function to determine if a Random Forrest Classifier is returned.\n",
    "    '''\n",
    "\n",
    "    data = random_data()\n",
    "    train, test = train_test_split(data, test_size=0.20, random_state=42)\n",
    "    \n",
    "    cat_features = [\n",
    "        'category_1',\n",
    "        'category_2',\n",
    "        'category_3',\n",
    "        'category_4',\n",
    "        'category_5',\n",
    "        'category_6'\n",
    "    ]\n",
    "    \n",
    "    X_train, y_train, encoder, lb = process_data(\n",
    "    X=train, categorical_features=cat_features, label=\"target\", training=True\n",
    "    )\n",
    "\n",
    "    model = train_model(X_train, y_train)\n",
    "    \n",
    "    assert type(model) == RandomForestClassifier\n",
    "    assert isinstance(model, BaseEstimator)\n",
    "    assert isinstance(model, ClassifierMixin)\n",
    "    \n",
    "    print(type(model))\n",
    "    print(isinstance(model, BaseEstimator))\n",
    "    print(isinstance(model, ClassifierMixin))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfe09c1f-c1cb-4fb9-a428-a754762130f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "test_train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff599973-a670-465a-8230-85c1972818d4",
   "metadata": {},
   "source": [
    "<H3>6. Test Model Inference</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d80aa278-01c1-4653-8761-4edcac806cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inference(model, X):\n",
    "\n",
    "    preds = model.predict(X)\n",
    "    return preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55d461e2-39c8-4ed6-a8bc-698ef2e48238",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_inference():\n",
    "    '''\n",
    "    Test inference function to determine if the number of predictions is equel to the\n",
    "    size of the imput DataFrame.\n",
    "    '''\n",
    "\n",
    "    data = random_data()\n",
    "    train, test = train_test_split(data, test_size=0.20, random_state=42)\n",
    "    \n",
    "    cat_features = [\n",
    "        'category_1',\n",
    "        'category_2',\n",
    "        'category_3',\n",
    "        'category_4',\n",
    "        'category_5',\n",
    "        'category_6'\n",
    "    ]\n",
    "    \n",
    "    X_train, y_train, encoder, lb = process_data(\n",
    "    X=train, categorical_features=cat_features, label=\"target\", \n",
    "    training=True)\n",
    "\n",
    "    X_test, y_test, _, _ = process_data(\n",
    "    X=test, categorical_features=cat_features, label=\"target\",\n",
    "    training=False, encoder=encoder, lb=lb)\n",
    "\n",
    "    model = train_model(X_train, y_train)\n",
    "    preds = inference(model, X_test)\n",
    "    \n",
    "    assert X_test.shape[0] == 8191\n",
    "    assert preds.shape[0] == 8191\n",
    "    assert X_test.shape[0] == preds.shape[0]\n",
    "    \n",
    "    print(X_test.shape)\n",
    "    print(preds.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47ea2fcf-3c5e-4f71-9ac1-8f6c8bba3ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8191, 32)\n",
      "(8191,)\n"
     ]
    }
   ],
   "source": [
    "test_inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c26f59-fa00-412c-90c4-935081499b83",
   "metadata": {},
   "source": [
    "<H3>7. Test Model Metrics</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8879ccc-90c2-43fe-aac3-d15d2853dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_model_metrics(y, preds):\n",
    "\n",
    "    fbeta = fbeta_score(y, preds, beta=1, zero_division=1)\n",
    "    precision = precision_score(y, preds, zero_division=1)\n",
    "    recall = recall_score(y, preds, zero_division=1)\n",
    "    return precision, recall, fbeta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d880a04-7442-4c3b-b94d-1deac3ce8f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_compute_model_metrics():\n",
    "    '''\n",
    "    Test compute model metrics function to determine if reasonable metrics are returned for random data.\n",
    "    '''\n",
    "\n",
    "    data = random_data()\n",
    "    train, test = train_test_split(data, test_size=0.20, random_state=42)\n",
    "    \n",
    "    cat_features = [\n",
    "        'category_1',\n",
    "        'category_2',\n",
    "        'category_3',\n",
    "        'category_4',\n",
    "        'category_5',\n",
    "        'category_6'\n",
    "    ]\n",
    "    \n",
    "    X_train, y_train, encoder, lb = process_data(\n",
    "    X=train, categorical_features=cat_features, label=\"target\", \n",
    "    training=True)\n",
    "\n",
    "    X_test, y_test, _, _ = process_data(\n",
    "    X=test, categorical_features=cat_features, label=\"target\",\n",
    "    training=False, encoder=encoder, lb=lb)\n",
    "\n",
    "    model = train_model(X_train, y_train)\n",
    "    preds = inference(model, X_test)\n",
    "    \n",
    "    precision, recall, fbeta = compute_model_metrics(y_test, preds)\n",
    "    \n",
    "    assert round(precision, 1) == 0.7\n",
    "    assert round(recall, 1) == 0.9\n",
    "    assert round(fbeta, 1) == 0.8\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {fbeta:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcdbdd84-6b80-49a0-a8bc-a1236bbb0623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6724 | Recall: 0.8779 | F1: 0.7616\n"
     ]
    }
   ],
   "source": [
    "test_compute_model_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccf6a86-f6a4-495d-b32d-67b1d686b329",
   "metadata": {},
   "source": [
    "<H3>8. Test Categorical Slice</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4de8bae0-8fd4-438e-99d5-8d364b376a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def performance_on_categorical_slice(\n",
    "    data, column_name, slice_value, categorical_features, label, encoder, lb, model):\n",
    "\n",
    "    data_slice = data[data[column_name] == slice_value]\n",
    "\n",
    "    X_slice, y_slice, _, _ = process_data(\n",
    "        X = data_slice,\n",
    "        categorical_features = categorical_features, \n",
    "        label = label, \n",
    "        training = False, \n",
    "        encoder = encoder, \n",
    "        lb = lb\n",
    "    )\n",
    "    \n",
    "    preds = inference(model, X_slice)\n",
    "    precision, recall, fbeta = compute_model_metrics(y_slice, preds)\n",
    "    \n",
    "    return precision, recall, fbeta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edf13b01-809b-43e4-9c71-f604613186cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_performance_on_categorical_slice():\n",
    "    '''\n",
    "    Test performance on categorical slice function to determine if reasonable metrics are returned for random data.\n",
    "    '''\n",
    "\n",
    "    data = random_data()\n",
    "    train, test = train_test_split(data, test_size=0.20, random_state=42)\n",
    "    \n",
    "    cat_features = [\n",
    "        'category_1',\n",
    "        'category_2',\n",
    "        'category_3',\n",
    "        'category_4',\n",
    "        'category_5',\n",
    "        'category_6'\n",
    "    ]\n",
    "    \n",
    "    X_train, y_train, encoder, lb = process_data(\n",
    "    X=train, categorical_features=cat_features, label=\"target\", \n",
    "    training=True)\n",
    "\n",
    "    X_test, y_test, _, _ = process_data(\n",
    "    X=test, categorical_features=cat_features, label=\"target\",\n",
    "    training=False, encoder=encoder, lb=lb)\n",
    "\n",
    "    model = train_model(X_train, y_train)\n",
    "    preds = inference(model, X_test)\n",
    "    \n",
    "    precision, recall, fbeta = performance_on_categorical_slice(\n",
    "            data = test, \n",
    "            column_name = 'category_1', \n",
    "            slice_value = 'Alpha',\n",
    "            categorical_features = cat_features, \n",
    "            label = 'target',\n",
    "            encoder = encoder, \n",
    "            lb = lb, \n",
    "            model = model\n",
    "        )\n",
    "    \n",
    "    assert round(precision, 1) == 0.7\n",
    "    assert round(recall, 1) == 0.9\n",
    "    assert round(fbeta, 1) == 0.8\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {fbeta:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31d4f07a-dce6-4255-81ed-9ab0a8d198b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6689 | Recall: 0.8697 | F1: 0.7562\n"
     ]
    }
   ],
   "source": [
    "test_performance_on_categorical_slice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505eb9dd-0547-4d75-8a14-0f92c8b20327",
   "metadata": {},
   "source": [
    "<H3>9. Streamline Tests</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77b5b4af-690d-4380-a2ef-de31a00fa036",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_samples(data_values):\n",
    "    '''\n",
    "    Creates data and model for testing purposes.\n",
    "    '''\n",
    "\n",
    "    print('Creating Random Data')\n",
    "    data = random_data()\n",
    "\n",
    "    if data_values == 'random_data':\n",
    "        return data\n",
    "\n",
    "    print('Creating Data Split')\n",
    "    train, test = train_test_split(data, test_size=0.20, random_state=42)\n",
    "    \n",
    "    cat_features = [\n",
    "        'category_1',\n",
    "        'category_2',\n",
    "        'category_3',\n",
    "        'category_4',\n",
    "        'category_5',\n",
    "        'category_6'\n",
    "    ]\n",
    "\n",
    "    if data_values == 'process_training_data':\n",
    "        return train, cat_features\n",
    "\n",
    "    print('Processing Training Data')\n",
    "    X_train, y_train, encoder, lb = process_data(\n",
    "    X=train, categorical_features=cat_features, label=\"target\", \n",
    "    training=True)\n",
    "\n",
    "    if data_values == 'model_data':\n",
    "        return X_train, y_train\n",
    "    \n",
    "    print('Processing Testing Data')\n",
    "    X_test, y_test, _, _ = process_data(\n",
    "    X=test, categorical_features=cat_features, label=\"target\",\n",
    "    training=False, encoder=encoder, lb=lb)\n",
    "\n",
    "    print('Creating ML Model')\n",
    "    model = train_model(X_train, y_train)\n",
    "\n",
    "    if data_values == 'inference_data':\n",
    "        return X_test, model\n",
    "\n",
    "    print('Gathering Inferences')\n",
    "    preds = inference(model, X_test)\n",
    "\n",
    "    if data_values == 'metrics_data':\n",
    "        return y_test, preds\n",
    "\n",
    "    if data_values == 'slice_data':\n",
    "        return test, cat_features, encoder, lb, model\n",
    "\n",
    "    print('Computing Model Metrics')\n",
    "    precision, recall, fbeta = compute_model_metrics(y_test, preds)\n",
    "    \n",
    "    precision, recall, fbeta = performance_on_categorical_slice(\n",
    "            data = test, \n",
    "            column_name = 'category_1', \n",
    "            slice_value = 'Alpha',\n",
    "            categorical_features = cat_features, \n",
    "            label = 'target',\n",
    "            encoder = encoder, \n",
    "            lb = lb, \n",
    "            model = model\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38f15705-6dc1-4150-befe-26b569d9ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data Split\n",
    "\n",
    "def test_data_split():\n",
    "    '''\n",
    "    Test train_test_split to determine if train and test data are split approx 80/20.\n",
    "    '''\n",
    "\n",
    "    # Get Sample Data\n",
    "    data = test_samples('random_data')\n",
    "\n",
    "    # Split Sample Data\n",
    "    train, test = train_test_split(data, test_size=0.20, random_state=42)\n",
    "    \n",
    "    assert type(train) == pd.core.frame.DataFrame\n",
    "    assert type(test) == pd.core.frame.DataFrame\n",
    "    \n",
    "    assert train.shape[0] == int(data.shape[0] * .80)\n",
    "    assert test.shape[0] == math.ceil(data.shape[0] * .20)\n",
    "\n",
    "    print(type(train))\n",
    "    print(type(test))\n",
    "    print(train.shape)\n",
    "    print(test.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08eb3722-083c-4915-97f2-e83862ab8ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Random Data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(32761, 11)\n",
      "(8191, 11)\n"
     ]
    }
   ],
   "source": [
    "test_data_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4a85f99-c0f6-41d8-a678-a20148134c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Process Data\n",
    "\n",
    "def test_process_data():\n",
    "    \n",
    "    '''\n",
    "    Test process_data function to determine if correct data types are returned.\n",
    "    '''\n",
    "\n",
    "    # Get Data Samples\n",
    "    train, cat_features = test_samples('process_training_data')\n",
    "\n",
    "    # Process Sample Data\n",
    "    X_train, y_train, encoder, lb = process_data(\n",
    "    X=train, categorical_features=cat_features, label=\"target\", training=True\n",
    "    )\n",
    "    \n",
    "    assert type(X_train) == np.ndarray\n",
    "    assert X_train.shape[0] == train.shape[0]\n",
    "\n",
    "    assert type(y_train) == np.ndarray\n",
    "    assert y_train.shape[0] == train.shape[0]\n",
    "\n",
    "    assert type(encoder) == OneHotEncoder\n",
    "    assert type(lb) == LabelBinarizer\n",
    "\n",
    "    \n",
    "    print(type(X_train))\n",
    "    print(X_train.shape)\n",
    "    \n",
    "    print(type(y_train))\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    print(type(encoder))\n",
    "    print(type(lb))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32515cde-c697-46f5-bbc9-427b23840ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Random Data\n",
      "Creating Data Split\n",
      "<class 'numpy.ndarray'>\n",
      "(32761, 32)\n",
      "<class 'numpy.ndarray'>\n",
      "(32761,)\n",
      "<class 'sklearn.preprocessing._encoders.OneHotEncoder'>\n",
      "<class 'sklearn.preprocessing._label.LabelBinarizer'>\n"
     ]
    }
   ],
   "source": [
    "test_process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b8e3623-ce0d-4fbf-9f8b-215ac0a51fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model\n",
    "\n",
    "def test_train_model():\n",
    "    '''\n",
    "    Test train_model function to determine if a Random Forrest Classifier is returned.\n",
    "    '''\n",
    "\n",
    "    # Get Sample Data\n",
    "    X_train, y_train = test_samples('model_data')\n",
    "\n",
    "    # Create ML Model\n",
    "    model = train_model(X_train, y_train)\n",
    "    \n",
    "    assert type(model) == RandomForestClassifier\n",
    "    assert isinstance(model, BaseEstimator)\n",
    "    assert isinstance(model, ClassifierMixin)\n",
    "    \n",
    "    print(type(model))\n",
    "    print(isinstance(model, BaseEstimator))\n",
    "    print(isinstance(model, ClassifierMixin))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "143fdd7c-db31-4e16-a5b3-56cfe289c449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Random Data\n",
      "Creating Data Split\n",
      "Processing Training Data\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "test_train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bb77d11-009c-47d6-a6ea-2cfa758e50b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Inference\n",
    "\n",
    "def test_inference():\n",
    "    '''\n",
    "    Test inference function to determine if the number of predictions is equel to the\n",
    "    size of the imput DataFrame.\n",
    "    '''\n",
    "\n",
    "    # Get Sample Data\n",
    "    X_test, model = test_samples('inference_data')\n",
    "\n",
    "    # Get Predictions\n",
    "    preds = inference(model, X_test)\n",
    "    \n",
    "    assert X_test.shape[0] == 8191\n",
    "    assert preds.shape[0] == 8191\n",
    "    assert X_test.shape[0] == preds.shape[0]\n",
    "    \n",
    "    print(X_test.shape)\n",
    "    print(preds.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "917b7363-1d70-45ad-93eb-a6c4cc23175e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Random Data\n",
      "Creating Data Split\n",
      "Processing Training Data\n",
      "Processing Testing Data\n",
      "Creating ML Model\n",
      "(8191, 32)\n",
      "(8191,)\n"
     ]
    }
   ],
   "source": [
    "test_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "673ab51f-c456-427c-aa06-79d208649232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model Metrics\n",
    "\n",
    "def test_compute_model_metrics():\n",
    "    '''\n",
    "    Test compute model metrics function to determine if reasonable metrics are returned for random data.\n",
    "    '''\n",
    "    # Get Sampale Data\n",
    "    y_test, preds = test_samples('metrics_data')\n",
    "\n",
    "    # Compute Metrics\n",
    "    precision, recall, fbeta = compute_model_metrics(y_test, preds)\n",
    "    \n",
    "    assert round(precision, 1) == 0.7\n",
    "    assert round(recall, 1) == 0.9\n",
    "    assert round(fbeta, 1) == 0.8\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {fbeta:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53039790-ce29-46ee-96de-ae0a9a63b3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Random Data\n",
      "Creating Data Split\n",
      "Processing Training Data\n",
      "Processing Testing Data\n",
      "Creating ML Model\n",
      "Gathering Inferences\n",
      "Precision: 0.6708 | Recall: 0.8786 | F1: 0.7607\n"
     ]
    }
   ],
   "source": [
    "test_compute_model_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "583b2046-e478-432f-a3b8-0393d11e74c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Categorical Slice\n",
    "\n",
    "\n",
    "def test_performance_on_categorical_slice():\n",
    "    '''\n",
    "    Test performance on categorical slice function to determine if reasonable metrics are returned for random data.\n",
    "    '''\n",
    "\n",
    "    # Get Sampale Data\n",
    "    test, cat_features, encoder, lb, model = test_samples('slice_data')\n",
    "\n",
    "    # Compute Slice Metrics\n",
    "    precision, recall, fbeta = performance_on_categorical_slice(\n",
    "            data = test, \n",
    "            column_name = 'category_1', \n",
    "            slice_value = 'Alpha',\n",
    "            categorical_features = cat_features, \n",
    "            label = 'target',\n",
    "            encoder = encoder, \n",
    "            lb = lb, \n",
    "            model = model\n",
    "        )\n",
    "    \n",
    "    assert round(precision, 1) == 0.7\n",
    "    assert round(recall, 1) == 0.9\n",
    "    assert round(fbeta, 1) == 0.8\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {fbeta:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbedd25b-3ce9-4a22-87b7-bd77cab49be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Random Data\n",
      "Creating Data Split\n",
      "Processing Training Data\n",
      "Processing Testing Data\n",
      "Creating ML Model\n",
      "Gathering Inferences\n",
      "Precision: 0.6701 | Recall: 0.8643 | F1: 0.7549\n"
     ]
    }
   ],
   "source": [
    "test_performance_on_categorical_slice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757b3bd-7ddc-478a-8c71-94e8ca276de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
